{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f4cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GenAI\\ChatGPT-Knowledge-Base\\venv\\lib\\site-packages\\langchain\\llms\\openai.py:169: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "D:\\GenAI\\ChatGPT-Knowledge-Base\\venv\\lib\\site-packages\\langchain\\llms\\openai.py:682: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), '.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "pdf_path = os.getenv('PDF_PATH')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_name = os.getenv('MODEL_NAME')\n",
    "\n",
    "# location of the pdf file/files. \n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits. \n",
    "\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "# expose this index in a retriever interface\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})\n",
    "\n",
    "# create a chain to answer questions \n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(model_name=model_name), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c01930",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what this book is about?\"\n",
    "result = qa({\"query\": query})['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88eb5b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This book is about writing modern Apache Spark applications using all the available tools in the project. It is designed for data scientists and data engineers looking to use Apache Spark and focuses more on application development than on operations and administration. The book places less emphasis on the older, lower-level APIs in Spark and is not the best fit if you need to maintain an old RDD or DStream application, but should be a great introduction to writing new applications.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e4402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f35415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea50e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f60b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), '.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "pdf_path = os.getenv('PDF_PATH')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_name = os.getenv('MODEL_NAME')\n",
    "\n",
    "# location of the pdf file/files. \n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "\n",
    "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits. \n",
    "\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "# expose this index in a retriever interface\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})\n",
    "\n",
    "# create a chain to answer questions \n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(model_name=model_name), chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "\n",
    "\n",
    "def ask_question():\n",
    "    query = question_entry.get()\n",
    "    result = qa({\"query\": query})\n",
    "    answer_text.delete(\"1.0\", tk.END)\n",
    "    answer_text.insert(tk.END, result['result'])\n",
    "\n",
    "# create a tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Question Answering App\")\n",
    "\n",
    "# create a label for the question\n",
    "question_label = tk.Label(window, text=\"Enter your question:\")\n",
    "question_label.pack()\n",
    "\n",
    "# create an entry field for the question\n",
    "question_entry = tk.Entry(window)\n",
    "question_entry.pack()\n",
    "\n",
    "# create a button to ask the question\n",
    "ask_button = tk.Button(window, text=\"Ask\", command=ask_question)\n",
    "ask_button.pack()\n",
    "\n",
    "# create a label for the answer\n",
    "answer_label = tk.Label(window, text=\"Answer:\")\n",
    "answer_label.pack()\n",
    "\n",
    "# create a text box to display the answer\n",
    "answer_text = tk.Text(window)\n",
    "answer_text.pack()\n",
    "\n",
    "# run the tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c084da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
